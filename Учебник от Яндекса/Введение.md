**Машинное обучение** - это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту.

Есть задачи, которые компьютер может решить сравнительно быстро, а люди наоборот справляются плохо. Однако не для каждой задачи можно написать эффективную программу, так, например, *NP-тредных задачи* нельзя решить за разумное время (это можно доказать). Однако есть и задачи, которые для людей не составляют особого труда, но которые сложно запрограммировать. Например:

- перевод текста с одного языка на другой;
- сказать, что изображено на картинке;
- диагностировать болезнь по симптомам.

Все эти задачи объединяет то, что их можно записать как функцию, которая отображает **объекты / примеры (samples)** в **предсказания (targets)**; также у этих задач нет единственно верного идеального решения; у нас есть много примеров правильных ответов, а примеры неправильных ответов можно легко сконструировать. Назовём функцию, отображающую объекты в предсказания, - **моделью**, а имеющийся набор примеров - **датасетом**. Датасет состоит из:

- **объектов** (например, картинки из интернета);
- **ответов** (подписи к картинкам) или **таргетов**.

### Постановка задачи

Описанные выше задачи являются примерами задач **обучения с учителем (supervised learning)**, т.к. правильные ответы для каждого объекта обучающей выборки заранее известны. Такие задачи делятся на следующие виды в зависимости от того, каким может быть множество $y$ всех возможных ответов / таргетов:

1. $\mathbb{Y} = \mathbb{R}$ или $\mathbb{Y} = \mathbb{R}^M$ - **регрессия**. Например, предсказание спроса на конкретный товар в конкретный день;
2. $\mathbb{Y} = \{0, 1\}$ - **бинарная классификация**. Например, мы можем предсказать, вернёт ли клиент кредит в установленный срок или нет;
3. $\mathbb{Y} = \{1, ..., K\}$ - **многоклассовая классификация с пересекающимися классами (multilabel classification)**. Например, задача автоматического проставления тегов для ресторанов (ресторан может иметь одновременно несколько тегов).
4. $\mathbb{Y}$ - конечное упорядоченное множество - **ранжирование**. Например, задача ранжирования поисковой выдачи, где необходимо отсортировать документы по релевантности запросу. При этом объекты сравниваются между собой, а абсолютное значение оценки релевантности не имеет значения.

Ответ может быть и более сложным. Так, в задаче сегментации изображения требуется для каждого пикселя предсказать, к какому объекту или типу объектов он относится, а в задаче машинного перевода мы должны сгенерировать предложение (или целый текст), являющееся переводом исходного. Интерес представляют и задачи **порождения новых объектов**, то есть генерации правдоподобных объектов, из ничего или на основе уже существующих. С помощью такой модели также можно научиться увеличивать разрешение изображения и применять любимые всеми маски в Snapchat или Instagram.

Есть и класс задач, относящихся к **обучению без учителя (unsupervised learning)**, - это задачи, для которых нам известны только данные, но неизвестны ответы. Например, кластеризация - задача разделения объектов на группы, обладающие определенными свойствами.

Бывают и другие виды и парадигмы МО.

### Критерии качества

По обучающей выборке мы хотим построить модель, предсказания которой достаточно хороши. От цели зависит и выбор **метрик качества**. В каждом конкретном случае может возникать целая иерархия метрик.

1. Самый верхний уровень - это **бизнес-метрики**, например, будущий доход сервиса. Их трудно измерить в моменте, они сложным образом зависят от совокупности всех наших училий, даже возможно не связанных с МО.
2. **Онлайн метрики** - это характеристики работающей системы, с помощью которых мы пытаемся оценить, что будет с бизнес-метриками. Например, медианная длина сессии в онлайн-игре. Можно предположить, что пользователь, который долго сидит в игре.
3. Для оценки субъективную реакцию людей на продукт, например, нанимаются специальные люди - асессоры. Так, например, можно оценить качество машинного перевода.
4. **Офлайн метрики** могут быть измерены до введения модели в эксплуатацию, например, по историческим данным. В задачах, в которых нужно предсказывать таргет, офлайн метрики обычно оценивают отклонение предсказаний модели от истинных значений таргета.

Асессорскую оценку тоже можно считать офлайн-метрикой.

Цель обычно состоит в том, чтобы найти модель с оптимальным значением метрики.

Критерии качвества не всегда сводятся к метрикам. Бизнес или общество могут накладывать и другие требования, например:

- модель может выдавать предсказания в режиме реального времени;
- модель достаточно компактна для телефонов;
- аргументация предсказания;
- нет дискриминации.

### Данные

Машинное обучение начинается с данных. Важно, чтобы их было достаточно много и они были достаточно качественными. Причем, чем сложнее задача, тем больше данных нужно. Бороться с проблемой нехватки данных можно 2 способами:

- использование **краудсорсинга**, т.е. привлечение людей, готовых разметить много данных / использование **citizen science** - разметки данных волонтерами;
- использование неразмеченных данных. Например, в задаче аннотирования изображений есть огромное количество не связанных друг с другом изображений и текстов. Но мы можем использовать их для того, чтобы помочь компьютеру понять, какие слова в принципе могут стоять рядом в предложении. Подходы, связанные с использованием неразмеченных данных для решения задач обучения с учителем, объединяются термином **self-supervised learning**. Важной составляющей является **обучение представлений (representation learning)** - задача построения компактных векторов небольшой размерности из сложных по структуре данных.

- Но помимо количества данных также важно их удобство для анализа. Для работы с объектом модель должна опираться на какие-то его свойства, например, доход человека или частота встречаемости слова "интеграл" в тексте. Эти свойства называются **признаками**, а совокупность свойств - **признаковым описанием**. Вот несколько простых и распространенных разновидностей признаков:

- **численные** - например, доход;
- **категориальные** - принимают значения из дискретного множества;
- **бинарные признаки** - прнимают значения 0 и 1 - могут быть как численными, так и категориальными;
- **ординальные** - подвид категориальных - принимают значения из упорядоченного дискретного множества (например, класс опасности химического вещества).

Часто приходится иметь дело и с более сложно устроенными признаками. Если такие попадаются, то могут потребоваться дополнительные усилия для извлечения из них признаков - этот процесс называется **feature engineering**.

Самые удобные для работы представления данных - **таблитчные** (очевидно представлены в виде таблиц). Но есть также и другие варианты для текстов, звука, изображений и т.д.

Лучше всего, если все признаки являются численными. Тогда с таблицей можно работать как с объектом линейной алгебры - матрицей объекты-признаки.

Создание информативного признакового описания очень важно для дальнейшего анализа. Но нужно также следить и за качеством полученных данных. Могут, например, встретиться следующие проблемы:

- **пропуски**;
- **выбросы**;
- ошибки разметки;
- **data drift** - с течением времени данные могут меняться. Например, может измениться схема сбора данных, поменяется формат данных или может измениться распределение данных.

Встречаются и другие проблемы.

### Модель и алгоритм обучения

Модель - это некоторый способ описания мира. Причем описание одного и того же объекта может меняться в зависимости от требуемой точности и доступной техники. Для некоторых задач будет избыточным максимально точное описание объекта.

Пусть $y = f_{\omega}(x)$ - класс предсказательных моделей, где $\omega$ - параметры, которые мы будем подбирать по данным.

Для примера возьмем задачу предсказания цены квартиры. В качестве класса моделей выберем константные функции $f(x) = c$ (т.е. будет для всех квартир предсказывать одно и то же значение цены). Посколько значение не зависит от $x$, нам неважно в каком виде было получено признаковое описание. Будем оценивать метрику качества - **среднее абсолютное отклонение (mean absolute error) - $MAE$**.

$MAE(f, X, y) = L(f, X, y) = \cfrac{1}{N}$
