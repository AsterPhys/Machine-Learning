**Машинное обучение** - это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту.

Есть задачи, которые компьютер может решить сравнительно быстро, а люди наоборот справляются плохо. Однако не для каждой задачи можно написать эффективную программу, так, например, *NP-тредных задачи* нельзя решить за разумное время (это можно доказать). Однако есть и задачи, которые для людей не составляют особого труда, но которые сложно запрограммировать. Например:

- перевод текста с одного языка на другой;
- сказать, что изображено на картинке;
- диагностировать болезнь по симптомам.

Все эти задачи объединяет то, что их можно записать как функцию, которая отображает **объекты / примеры (samples)** в **предсказания (targets)**; также у этих задач нет единственно верного идеального решения; у нас есть много примеров правильных ответов, а примеры неправильных ответов можно легко сконструировать. Назовём функцию, отображающую объекты в предсказания, - **моделью**, а имеющийся набор примеров - **датасетом**. Датасет состоит из:

- **объектов** (например, картинки из интернета);
- **ответов** (подписи к картинкам) или **таргетов**.

### Постановка задачи

Описанные выше задачи являются примерами задач **обучения с учителем (supervised learning)**, т.к. правильные ответы для каждого объекта обучающей выборки заранее известны. Такие задачи делятся на следующие виды в зависимости от того, каким может быть множество $y$ всех возможных ответов / таргетов:

1. $\mathbb{Y} = \mathbb{R}$ или $\mathbb{Y} = \mathbb{R}^M$ - **регрессия**. Например, предсказание спроса на конкретный товар в конкретный день;
2. $\mathbb{Y} = \{0, 1\}$ - **бинарная классификация**. Например, мы можем предсказать, вернёт ли клиент кредит в установленный срок или нет;
3. $\mathbb{Y} = \{1, ..., K\}$ - **многоклассовая классификация с пересекающимися классами (multilabel classification)**. Например, задача автоматического проставления тегов для ресторанов (ресторан может иметь одновременно несколько тегов).
4. $\mathbb{Y}$ - конечное упорядоченное множество - **ранжирование**. Например, задача ранжирования поисковой выдачи, где необходимо отсортировать документы по релевантности запросу. При этом объекты сравниваются между собой, а абсолютное значение оценки релевантности не имеет значения.

Ответ может быть и более сложным. Так, в задаче сегментации изображения требуется для каждого пикселя предсказать, к какому объекту или типу объектов он относится, а в задаче машинного перевода мы должны сгенерировать предложение (или целый текст), являющееся переводом исходного. Интерес представляют и задачи **порождения новых объектов**, то есть генерации правдоподобных объектов, из ничего или на основе уже существующих. С помощью такой модели также можно научиться увеличивать разрешение изображения и применять любимые всеми маски в Snapchat или Instagram.

Есть и класс задач, относящихся к **обучению без учителя (unsupervised learning)**, - это задачи, для которых нам известны только данные, но неизвестны ответы. Например, кластеризация - задача разделения объектов на группы, обладающие определенными свойствами.

Бывают и другие виды и парадигмы МО.

### Критерии качества

По обучающей выборке мы хотим построить модель, предсказания которой достаточно хороши. От цели зависит и выбор **метрик качества**. В каждом конкретном случае может возникать целая иерархия метрик.

1. Самый верхний уровень - это **бизнес-метрики**, например, будущий доход сервиса. Их трудно измерить в моменте, они сложным образом зависят от совокупности всех наших училий, даже возможно не связанных с МО.
2. **Онлайн метрики** - это характеристики работающей системы, с помощью которых мы пытаемся оценить, что будет с бизнес-метриками. Например, медианная длина сессии в онлайн-игре. Можно предположить, что пользователь, который долго сидит в игре 
3. 
